{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "690f98f7-648f-4146-8aa4-6a47fbb72883",
    "_uuid": "d6576d078c298c71f783ae570d9e1941be2924ed"
   },
   "source": [
    "# Análise de Sentimentos em língua portuguesa do Brasil\n",
    "\n",
    "Exemplo didático de análise de sentimentos a partir de uma base de dados de tweets classificados classificados como positivo, negativo e neutro. Baseado no trabalho do Minerando Dados (https://github.com/minerandodados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6f03ca1a-3c0e-4e33-9ba6-91a9d640185f",
    "_uuid": "2840dd041b764e287b641cc8308c68c520796d9b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"-l\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a9cdc1e8-0e19-4f98-a377-1a8efa50331c",
    "_uuid": "af447214f6b3b7791f19e4a17488198659a5e6ab"
   },
   "source": [
    "## 1. O Dataset de Tweets\n",
    "Vamos começar inspecionando nosso dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f1f48f72-4db1-4734-8723-9ef52aedc7b0",
    "_uuid": "7b761277e1b96610ba67f19b27b52d6658acd2bb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Primeiro, vamos contar a quantidade total de registros\n",
    "dataset = pd.read_csv('../input/Tweets_Mg.csv',encoding='utf-8')\n",
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f2cfc532-207d-4d45-9110-bfefafa97b2a",
    "_uuid": "cf33f8ba0a1faf5aced6cb0769d39407ac08ee76",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Agora, apenas os classificados como neutro\n",
    "dataset[dataset.Classificacao == 'Neutro'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e3d854fb-edab-4a8c-a22a-c41782f1db5a",
    "_uuid": "ab681c0af0991060c8b176adf95d0438097715f9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Os classificados como positivo\n",
    "dataset[dataset.Classificacao == 'Positivo'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1241d7f5-12c6-4f4f-9c0f-4355f1195d8f",
    "_uuid": "d8c95fe8a2ff1114161f3af20a87dfabb80d3048",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# E finalmente, os classificados como negativo\n",
    "dataset[dataset.Classificacao == 'Negativo'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "978a0209-71be-443d-8748-88f7c1cef6c5",
    "_uuid": "7c04a528851a3fa57b89a1ad33826456a423e7f0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OK, vamos dar uma olhada rápida no conteúdo do dataset para finalizar esse passo\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f39fe03f-981f-4629-b79a-50098dd59924",
    "_uuid": "73de912a022494b152d915d3ea31ca18c14d718b"
   },
   "source": [
    "## 2. Construindo o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eca2a77a-f355-41c5-ad4a-dfbe32af62f4",
    "_uuid": "0b90c933012a38041e975f66a60f377915b92112",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Próximo passo, vamos separar os tweets e suas classes\n",
    "tweets = dataset[\"Text\"].values\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "69e04867-3f0f-47d2-88f5-df2127042d1b",
    "_uuid": "866709548dc8dabc53c1c758f0bfdf410182a19d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = dataset[\"Classificacao\"].values\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "007fbaef-b5d0-4fd7-92cc-2583ba668179",
    "_uuid": "a376262987475125694411ecb7e129f07e84e8f3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Agora, vamos treinar o modelo usando a abordagem Bag of Words e o algoritmo Naive Bayes Multinomial\n",
    "#    - Bag of Words, na prática, cria um vetor com cada uma das palavras do texto completo da base,\n",
    "#      depois, calcula a frequência em que essas palavras ocorrem em uma data sentença, para então\n",
    "#      classificar/treinar o modelo\n",
    "#    - Exemplo HIPOTÉTICO de três sentenças vetorizadas \"por palavra\" e classificadas baseada na\n",
    "#      frequência de suas palavras:\n",
    "#         {0,3,2,0,0,1,0,0,0,1, Positivo}\n",
    "#         {0,0,1,0,0,1,0,1,0,0, Negativo}\n",
    "#         {0,1,1,0,0,1,0,0,0,0, Neutro}\n",
    "#    - Olhando para esses vetores, meu palpite é que as palavras nas posições 2 e 3 são as com maior\n",
    "#      peso na determinação de a que classe pertence cada uma das três sentenças avaliadas\n",
    "#    - A função fit_transform faz exatamente esse processo: ajusta o modelo, aprende o vocabulário,\n",
    "#      e transforma os dados de treinamento em feature vectors, a.k.a. vetor com frequêcia das palavras\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\")\n",
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "466d7f29-032e-4dec-9602-94dd38109d3a",
    "_uuid": "f55fb6c880a34170862eaf35be8f594d9e280460"
   },
   "source": [
    "## 3. Testando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "455dcddd-6b44-4a28-97c3-fa08f0fee171",
    "_uuid": "68bc8d6fc38abf056dca0a39b687d1c381f8fd25",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vamos usar algumas frases de teste para fazer a classificação com o modelo treinado\n",
    "testes = [\"Esse governo está no início, vamos ver o que vai dar\",\n",
    "          \"Estou muito feliz com o governo de São Paulo esse ano\",\n",
    "          \"O estado de Minas Gerais decretou calamidade financeira!!!\",\n",
    "          \"A segurança desse país está deixando a desejar\",\n",
    "          \"O governador de Minas é do PT\",\n",
    "          \"O prefeito de São Paulo está fazendo um ótimo trabalho\"]\n",
    "\n",
    "freq_testes = vectorizer.transform(testes)\n",
    "modelo.predict(freq_testes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "179b67d3-0050-4188-a605-b70907e14336",
    "_uuid": "170c7c69f73a7433a0554d44a98a62308e08fc9f"
   },
   "source": [
    "## 4. Avaliando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6afb7e0c-ce1c-497b-8f2f-02b75587954e",
    "_uuid": "7cff21dfc9bb07fbce32ab78ed3073b13bdc021b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validação cruzada do modelo. Neste caso, o modelo é dividido em 10 partes, treinado em 9 e testado em 1\n",
    "resultados = cross_val_predict(modelo, freq_tweets, classes, cv = 10)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b6b63681-0961-4da4-bd40-3c73cf0884cd",
    "_uuid": "e8eb430cb4d6449c8f173c27fbac4fc4ec711bb3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quão acurada é a média do modelo?\n",
    "metrics.accuracy_score(classes, resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a2b917b7-da10-4403-b0a7-f6f88897e29d",
    "_uuid": "1fb21da856cc6c4ee65f7daa95137dcdfbb51c0d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Medidas de validação do modelo\n",
    "sentimentos = [\"Positivo\", \"Negativo\", \"Neutro\"]\n",
    "print(metrics.classification_report(classes, resultados, sentimentos))\n",
    "\n",
    "# Lembrando que:\n",
    "#    : precision = true positive / (true positive + false positive)\n",
    "#    : recall    = true positive / (true positive + false negative)\n",
    "#    : f1-score  = 2 * ((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ffda64a4-e0cf-443c-bb53-a1a6f2024ae1",
    "_uuid": "aaa2cc41ea529a09c8a3c8fe504457b02769ea59",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vamos fazer uma matriz de confusão -- What?!?!\n",
    "print(pd.crosstab(classes, resultados, rownames = [\"Real\"], colnames=[\"Predito\"], margins=True))\n",
    "\n",
    "# Lembrando que:\n",
    "#    - Predito = O que o programa classificou como Negativo, Neutro, Positivo e All\n",
    "#    - Real    = O que é de fato Negativo, Neutro, Positivo e All\n",
    "#\n",
    "# Ou seja, somente 9 tweets eram de fato negativos e o programa classificou como positivos. Já os\n",
    "# positivos que o programa classificou como negativos foram 45, muito mais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0354f18c-b26d-42e9-b5b8-945b931cc2a0",
    "_uuid": "0c355e4fb76bd97a114473c71a49872dcd5b5c75"
   },
   "source": [
    "## 5. Melhorando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8dfc7e26-78fe-4233-89db-3795d4c360bd",
    "_uuid": "c4db254fe1fa38a0d05067708d37e65f007eb118",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Com o modelo de Bigrams, em lugar de vetorizar o texto \"por palavra\", vamos vetoriza-lo por cada\n",
    "# \"duas palavras\", tipo: Eu gosto de São Paulo => { eu gosto, gosto de, de são, são paulo }\n",
    "vectorizer = CountVectorizer(ngram_range = (1, 2))\n",
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e918cdc1-a49c-4868-9218-047af413b4c5",
    "_uuid": "a6b6fe306e4a46b24150f858d88fa9b49bb58575",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nova predição bigramada\n",
    "resultados = cross_val_predict(modelo, freq_tweets, classes, cv = 10)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eeac7ad5-01ee-495b-b014-a3cbeda59abc",
    "_uuid": "89647d6fedfb0d600c4d32bda31a95a4b7e6c83a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Qual foi a acuracidade desse novo modelo?\n",
    "metrics.accuracy_score(classes, resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ac06ba72-6bd4-41c7-8175-e1604f179ee5",
    "_uuid": "3ae3973a12114a23096b0d35dfa298c36340a901",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As novas medidas de validação do modelo, um pouquinho melhor que o anterior\n",
    "print(metrics.classification_report(classes, resultados, sentimentos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6ba7bd8e-30ea-42dc-929e-39bfc54ed323",
    "_uuid": "fcddb076247e620c096b02b7d5562a63d14c79ec",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# E a nova matriz de confusão\n",
    "print(pd.crosstab(classes, resultados, rownames = [\"Real\"], colnames = [\"Predito\"], margins = True))\n",
    "\n",
    "# Mudanças em relação ao modelo anterior:\n",
    "#\n",
    "#    - Negativo-negativo = 2275 vs 2265 (piorou)\n",
    "#    - Negativo-neutro   = 162  vs 179  (piorou)\n",
    "#    - Negativo-positivo = 9    vs 2    (melhorou)\n",
    "#\n",
    "#    - Positivo-positivo = 2899 vs 2900 (melhorou)\n",
    "#    - Positivo-neutro   = 356  vs 357  (piorou)\n",
    "#    - Positivo-negativo = 45   vs 43   (melhorou)\n",
    "#\n",
    "#    - Neutro-neutro     = 2067 vs 2177 (melhorou)\n",
    "#    - Neutro-negativo   = 240  vs 181  (melhorou)\n",
    "#    - Neutro-positivo   = 146  vs 95   (melhorou)\n",
    "#\n",
    "# Tabela anterior para referência:\n",
    "#\n",
    "#    Predito   Negativo  Neutro  Positivo   All\n",
    "#    Real                                      \n",
    "#    Negativo      2275     162         9  2446\n",
    "#    Neutro         240    2067       146  2453\n",
    "#    Positivo        45     356      2899  3300\n",
    "#    All           2560    2585      3054  8199"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e110fa95-d680-4be2-9eda-1270ef26b46c",
    "_uuid": "23667044df7fc4bc823e300200974a489d4fe80d"
   },
   "source": [
    "# Bônus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "37a22b03-e440-4ad4-8281-de61479ab563",
    "_uuid": "8da2509f419ffdfcfc0441af686d91a6b9eb90fa",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vamos reinicializar nosso bag of words com um parâmetro de máximo de features\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None,\n",
    "                             stop_words = None, max_features = 5000)\n",
    "\n",
    "# Treinar o modelo, aprender o vocabulário e transformar nossos dados de treinamento em feature vectors\n",
    "train_data_features = vectorizer.fit_transform(tweets)\n",
    "train_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "85de9639-ac4a-4934-a572-949001f190bd",
    "_uuid": "5b5372b7009069ca8dff959ae95137033cb3b25e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hora de iniciar um classificador Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7d9c25be-4942-4bf0-8cb0-f018a38edb09",
    "_uuid": "99f6f55b07fbac58fb42206feb8ef3526a21981d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separar os sentimentos do dataset de tweets\n",
    "class_sentimentos = dataset[\"Classificacao\"].values\n",
    "class_sentimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ff88013f-fbd2-4ec4-8ec6-cc7e45b4957a",
    "_uuid": "e65add0e8b5bbd16f5e819f4794ff728539551a2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ajusta a forest ao dataset de treinamento usando a bag of words como feature e os sentimentos\n",
    "# como a resposta variável\n",
    "forest = forest.fit(train_data_features, class_sentimentos)\n",
    "forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a05bc498-14b4-4f7f-b7a7-d308d0067ccd",
    "_uuid": "20aa2583db7ecf91e02bc945c6cdadde568abd63",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Criar a bag of words de teste\n",
    "test_data_features = vectorizer.transform(testes)\n",
    "test_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9e4a1300-7b5a-4f3d-ab27-d3c8f5f265ab",
    "_uuid": "de46ae32c3eeb3fd1fc1388d7573146516541100",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fazer um predição\n",
    "resultados = forest.predict(test_data_features)\n",
    "resultados\n",
    "\n",
    "# Resultado que tivemos com o primeiro modelo:\n",
    "# array(['Neutro', 'Neutro', 'Negativo', 'Negativo', 'Neutro', 'Positivo'], dtype='<U8')\n",
    "#\n",
    "# Meh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "05e502f3-c4ad-44e1-9480-eb7ce21202f0",
    "_uuid": "e824df8f567108ab50f2f39aba588612bfed3dd3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Que tal gerar uma tabelinha Pandas?\n",
    "testes_id = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "data_frame = pd.DataFrame(data = { \"id\": testes_id, \"texto\": testes, \"sentimento\": resultados })\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b2f278ac-2ff5-49dc-9461-b4b62d45c30a",
    "_uuid": "507f81f018ac63e1c7f46ac5140d178b0f3d8297",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# E finalmente, vamos salvar nossa predição em um .csv\n",
    "data_frame.to_csv(\"tweets_classificados_por_forest.csv\", index = False, quoting = 3, escapechar = \"\\\\\")\n",
    "print(check_output([\"ls\", \"-l\", \".\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5d1e2db8-a0b7-49de-ba13-f501cfc9d86d",
    "_uuid": "c4675aedf2a2e46b5642fbe8fd9f78c74a26cc74",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OK, ok, vamos dar só mais uma espiada para ver se deu tudo certo\n",
    "print(check_output([\"cat\", \"tweets_classificados_por_forest.csv\"]).decode(\"utf8\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
